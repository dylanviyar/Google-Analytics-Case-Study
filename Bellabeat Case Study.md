
# <img src="https://github.com/dylanviyar/Google-Analytics-Case-Study/assets/81194849/31b77307-1441-48d6-b089-3f4298a00545" alt="BellaBeat Logo" width="75"> Bellabeat Case Study: Making Marketing Data-Driven  
### Author: Dylan Viyar
### Last Updated: 2023-09-06




This case study is the final project of the Google Data Analytics Professional Certificate, hosted on Coursera. This analysis follows the data exploration process of *Ask, Prepare, Process, Analyze, Share, Act*


# 1: ASK

#### In this step, we ask meaningful, purposeful and insightful questions to clearly define the business task.

### 1.0 The Setting

Bellabeat is a high-tech manufacturer of health focused products for women, founded in 2013. The small company is looking to become a larger player in the wellness market, particularly in the realm of smart devices and wearable technology.

The executive staff at Bellabeat would like to conduct analysis on consumer usage of similar *non-Bellabeat* smart devices to gain insights on possible marketing strategies and opportnities.

### 1.1 Key Stakeholders

1. Urška Sršen: Cofounder of Bellabeat and Chief Creative Officer
2. Sando Mur: Cofounder of Bellabeat, Mathematician, and key member of Bellabeat's executive team
3. Bellabeat's Marketing Analytics Team: Team of data analysts working together to collect, analyze and report relevant data to supplement Bellabeat's marketing strategy.

### 1.2 Guiding Questions
*Note: When deciding what type of questions to ask to motivate analysis, it is important to ensure that the questions being asked are 'SMART' (**S**pecific, **M**easurable, **A**ction-orientated, **R**elevant, and **T**ime-bound)*

1. What are are some trends in smart device usage?
2. How can these trends apply to Bellabeat customers?
3. How can these trends ultimately influence the marketing strategy of Bellabeat?

### 1.3 Deliverables for the Case Study

1. A clear outline of the business task
2. A description of the data sources used
3. Documentation of any cleaning, manipulation or wrangling of the data
4. A summary of the analysis
5. Supplemental visualizations and key findings
6. A set of data-driven recommendations based on the analysis

### 1.4 The Business Task 

*Analyze FitBit Fitness Tracker Data on user's daily habits to identify trends in usage and how those trends can impact Bellabeat's marketing strategy.*

---

# 2. PREPARE

#### In this step, we determine the quality of the data we have to work with and understand the possible limitations of our analysis due to the data source.

### 2.0 Background Information on the Data Source

1. The dataset is open data; available to the public on Kaggle as  [FitBit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit)
2. The dataset was generated by 30 respondents to a distributed survey via Amazon Mechanical Turk through March 2016 to May 2016
3. The data includes information on heart rate, sleep monitoring, step, and heart rate, which can be used to explore users’ habits
4. The data is stored in 18 CSV files

### 2.1 Downloading the Data

1. In this case study, SQL is used as the main tool for processing analysis
2. The file chosen for exploration, `dailyActivity_merged.csv`, contains information about user fitness information specifically: distance, steps and minutes of activity

### 2.2 Possible Limitations of the Dataset

1. There is a high chance of sampling bias, 30 respondents may not accurately represent the total female population
2. The dataset was collected in 2016, trends identified may no longer be accurate to the current findings
3. Without access to the original survey, we cannot be confident that the data collection was done completely ethically and without bias
4. We do not have any information of the 30 women who's data were collected

### 2.3 Does the Data ROCC? 
*When evaluatiing the status of data to be used for analysis, a simple test is to see if the data you are using is 'ROCC' (**R**eliable, **O**riginal, **C**omprehensive, **C**urrent, **C**ited)*

1. Reliable: -*No*- We are unsure how well the sample represents the total population of women
2. Original : -*No*- The dataset is gathered from an external source (Amazon Mechanical Turk), it was not collected firsthand
3. Comprehensive: -*Yes*- The dataset has information relevant to Bellabeat, specfically metrics related to wearable technology, an area that Bellabeat wants to expand in
4. Current: -*No*- The data is from 2016, six years ago
5. Cited: -*No*- We are unsure how the external source cited the data

Our provided dataset does not 'ROCC,' thus further exploration and analysis is required to ensure the accurary of our findngs.

---

# 3. Process 
#### In this step, we clean our data; we ensure that the data is relevant, error-free and holds its integrity.

### 3.0 Understanding our SQL Table

1. To get an intial feel of our table we can run the following query to see the schema of our data and view all the column names as well as their data types:

```sql
SELECT column_name, data_type
FROM `kinetic-axle-394521.FitBit_Fitness_Tracker_Data.INFORMATION_SCHEMA.COLUMNS` 
WHERE table_name = 'DailyActivity'
```
<img src="https://github.com/dylanviyar/Google-Analytics-Case-Study/assets/81194849/1564dc03-b842-438f-a693-32a25feda963" alt="Daily Activity Table Column Names and DataTypes" width="300">

We see that there is a total of 15 columns with various data types in our table.

2. Now that we understand the columns of our table, we can query to view the first few rows to get a preview of the data and observe the values that the attributes have:

```sql
SELECT *
FROM `kinetic-axle-394521.FitBit_Fitness_Tracker_Data.DailyActivity` 
LIMIT 15 -- Retrieving first 15 rows only
```

![Daily Activity Head](https://github.com/dylanviyar/Google-Analytics-Case-Study/assets/81194849/c97c1f1f-848b-4409-9967-5f55f90b5dcb|width=300)

### 3.1 Cleaning our Data

Now that we have a basic idea of how our data looks and its characteristics, we can begin to process our data for analysis.
Some **Key Steps** include:
1. Dealing with Null and missing values
2. Removing duplicates
3. Checking for data type errors (inconsistent/mismatched data types)
4. Spell checking the data
5. Ensuring the data stays relevant to the business task






